{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing some commonly required libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import pickle\n",
    "import math\n",
    "import random\n",
    "import collections\n",
    "import os,glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from itertools import permutations\n",
    "\n",
    "from indicnlp.tokenize import sentence_tokenize\n",
    "from indicnlp.tokenize import indic_tokenize\n",
    "from indicnlp import common\n",
    "common.INDIC_RESOURCES_PATH=\"./../ExternalDependencies/indic_nlp_resources\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to files\n",
    "coherentPath='./../Data/Coherent'\n",
    "testPath='./../Data/Test'\n",
    "incoherentPath='./../Data/Incoherent'\n",
    "finalPath='./../Data/dataset_unbalanced.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable to change coherent to incoherent ratio\n",
    "no_of_shuffles = 10\n",
    "dataframe_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating coherent cliques\n",
    "for filename in glob.glob(os.path.join(coherentPath+'/DD', '*')):\n",
    "    with open(filename, 'r+') as f:\n",
    "      text = f.read()\n",
    "      myList=sentence_tokenize.sentence_split(text,lang='hi')\n",
    "      length = len(myList)\n",
    "      for index in range(0,length,3):\n",
    "          if index+2<length:\n",
    "            dataframe_list.append([myList[index]+myList[index+1]+myList[index+2], 1])\n",
    "\n",
    "for filename in glob.glob(os.path.join(coherentPath+'/Wiki', '*')):\n",
    "    with open(filename, 'r+') as f:\n",
    "      text = f.read()\n",
    "      myList=sentence_tokenize.sentence_split(text,lang='hi')\n",
    "      length = len(myList)\n",
    "      for index in range(0,length,3):\n",
    "          if index+2<length:\n",
    "            dataframe_list.append([myList[index]+myList[index+1]+myList[index+2], 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating incoherent cliques\n",
    "for filename in glob.glob(os.path.join(coherentPath+'/DD', '*')):\n",
    "    with open(filename, 'r+') as f:\n",
    "      text = f.read()\n",
    "      myList=sentence_tokenize.sentence_split(text,lang='hi')\n",
    "      length = len(myList)\n",
    "      for shuffle in range(no_of_shuffles):\n",
    "        random.shuffle(myList)\n",
    "        for index in range(0,length,3):\n",
    "            if index+2<length:\n",
    "                dataframe_list.append([myList[index]+myList[index+1]+myList[index+2], 0])\n",
    "\n",
    "for filename in glob.glob(os.path.join(coherentPath+'/Wiki', '*')):\n",
    "    with open(filename, 'r+') as f:\n",
    "      text = f.read()\n",
    "      myList=sentence_tokenize.sentence_split(text,lang='hi')\n",
    "      length = len(myList)\n",
    "      for shuffle in range(no_of_shuffles):\n",
    "        random.shuffle(myList)\n",
    "        for index in range(0,length,3):\n",
    "            if index+2<length:\n",
    "                dataframe_list.append([myList[index]+myList[index+1]+myList[index+2], 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(dataframe_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "MemoryError",
     "evalue": "Unable to allocate 34.0 GiB for an array with shape (275784, 2) and data type <U16561",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-a11d57bfc860>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 34.0 GiB for an array with shape (275784, 2) and data type <U16561"
     ]
    }
   ],
   "source": [
    "# generating dataframe\n",
    "df = pd.DataFrame(np.array(dataframe_list), columns = ['data', 'label']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing data to dataset csv\n",
    "df.to_csv(finalPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}